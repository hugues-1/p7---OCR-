{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "530cc79d-7655-4802-a839-52d871672f83",
   "metadata": {
    "id": "530cc79d-7655-4802-a839-52d871672f83"
   },
   "source": [
    "## ToDo : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f2e5131",
   "metadata": {
    "executionInfo": {
     "elapsed": 4035,
     "status": "ok",
     "timestamp": 1679413513647,
     "user": {
      "displayName": "Hugues Hansen",
      "userId": "06507793026638313555"
     },
     "user_tz": -60
    },
    "id": "9f2e5131",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importer les bibliothèques nécessaires\n",
    "\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix,accuracy_score\n",
    "import numpy as np\n",
    "import gc\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import missingno as msno\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import seaborn as sns\n",
    "import imblearn as imb\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer\n",
    "from imblearn import FunctionSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe044698",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18616,
     "status": "ok",
     "timestamp": 1679413532226,
     "user": {
      "displayName": "Hugues Hansen",
      "userId": "06507793026638313555"
     },
     "user_tz": -60
    },
    "id": "fe044698",
    "outputId": "2a523a59-8c6f-4418-fe2f-97945359ffd8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: shap in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (0.41.0)\n",
      "Requirement already satisfied: tqdm>4.25.0 in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from shap) (4.64.1)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from shap) (21.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from shap) (1.8.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from shap) (1.22.3)\n",
      "Requirement already satisfied: numba in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from shap) (0.56.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from shap) (1.1.1)\n",
      "Requirement already satisfied: slicer==0.0.7 in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from shap) (0.0.7)\n",
      "Requirement already satisfied: pandas in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from shap) (1.4.2)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from shap) (2.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from packaging>20.9->shap) (3.0.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>4.25.0->shap) (0.4.4)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from numba->shap) (0.39.1)\n",
      "Requirement already satisfied: setuptools<60 in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from numba->shap) (59.8.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from pandas->shap) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from pandas->shap) (2.8.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn->shap) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn->shap) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.1->pandas->shap) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install shap\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a24b06ad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46119,
     "status": "ok",
     "timestamp": 1679413578315,
     "user": {
      "displayName": "Hugues Hansen",
      "userId": "06507793026638313555"
     },
     "user_tz": -60
    },
    "id": "a24b06ad",
    "outputId": "5b90701b-debc-4637-ecad-de70959d1b94",
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    base=pd.read_csv(\"/content/drive/MyDrive/Notebooks/P7/basep7.csv\")\n",
    "        \n",
    "except ModuleNotFoundError :\n",
    "    \n",
    "    base = pd.read_csv(\"basep7.csv\")\n",
    "    \n",
    "base = base.drop( columns = ['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a90ebe0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1962,
     "status": "ok",
     "timestamp": 1679413580260,
     "user": {
      "displayName": "Hugues Hansen",
      "userId": "06507793026638313555"
     },
     "user_tz": -60
    },
    "id": "9a90ebe0",
    "outputId": "47a86b8c-1b29-4c38-b970-771bd9331546",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 122)\n",
      "(307511, 262)\n"
     ]
    }
   ],
   "source": [
    "# one_hot_encoder classique pour les non numériques\n",
    "def one_hot_encoder(base, nan_as_category = True):\n",
    "    original_columns = list(base.columns)\n",
    "    categorical_columns = [col for col in base.columns if base[col].dtype == 'object']\n",
    "    base2 = pd.get_dummies(base, columns= categorical_columns, dummy_na= True)\n",
    "    new_columns = [c for c in base.columns if c not in original_columns]\n",
    "    return base2\n",
    "print (base.shape)\n",
    "base2 =one_hot_encoder(base)\n",
    "print (base2.shape)\n",
    "base = base2\n",
    "del base2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95b1f4fe-9a96-4d9e-8ed7-fcc2ac13becf",
   "metadata": {
    "executionInfo": {
     "elapsed": 2177,
     "status": "ok",
     "timestamp": 1679413582422,
     "user": {
      "displayName": "Hugues Hansen",
      "userId": "06507793026638313555"
     },
     "user_tz": -60
    },
    "id": "95b1f4fe-9a96-4d9e-8ed7-fcc2ac13becf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remplacer les valeurs manquantes par la moyenne de la colonne\n",
    "base = base.fillna(base.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7aadae66-a87c-4bc0-b4c5-5bc4001ea36f",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1679413582424,
     "user": {
      "displayName": "Hugues Hansen",
      "userId": "06507793026638313555"
     },
     "user_tz": -60
    },
    "id": "7aadae66-a87c-4bc0-b4c5-5bc4001ea36f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Séparer les variables explicatives (X) et la variable cible (y)\n",
    "X = base.drop(\"TARGET\", axis=1)\n",
    "y = base[\"TARGET\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2eded73f-1548-4e31-8413-d36c34ead49e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10407,
     "status": "ok",
     "timestamp": 1679413592822,
     "user": {
      "displayName": "Hugues Hansen",
      "userId": "06507793026638313555"
     },
     "user_tz": -60
    },
    "id": "2eded73f-1548-4e31-8413-d36c34ead49e",
    "outputId": "daa3ce50-767b-4f9e-fa02-02065d57c321",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 261)\n"
     ]
    }
   ],
   "source": [
    "# scaler \n",
    "col_names=X.select_dtypes(include='number').columns.tolist()\n",
    "features = X[col_names]\n",
    "scaler = StandardScaler().fit(features.values)\n",
    "features_scale = scaler.transform(features.values)\n",
    "X[col_names] = features_scale\n",
    "print (X.shape) \n",
    "del features\n",
    "del features_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e06395-aa30-4107-9c5c-7f783de12ba2",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1679413592824,
     "user": {
      "displayName": "Hugues Hansen",
      "userId": "06507793026638313555"
     },
     "user_tz": -60
    },
    "id": "c5e06395-aa30-4107-9c5c-7f783de12ba2",
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e741f79e",
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1679413592825,
     "user": {
      "displayName": "Hugues Hansen",
      "userId": "06507793026638313555"
     },
     "user_tz": -60
    },
    "id": "e741f79e"
   },
   "outputs": [],
   "source": [
    "# Améliore l'affichage des DataFrame de résultats. \n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "439eaa0a-1eaa-4750-a336-7194d08965a3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "executionInfo": {
     "elapsed": 10521,
     "status": "ok",
     "timestamp": 1679413603333,
     "user": {
      "displayName": "Hugues Hansen",
      "userId": "06507793026638313555"
     },
     "user_tz": -60
    },
    "id": "3ohf4ulLOOIz",
    "outputId": "2071e4cd-c190-44a4-c478-74ccb44cffb8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "#X_resampled, y_resampled = RandomUnderSampler(random_state=22).fit_resample(X_train,y_train)\n",
    "X_train=X_train.sample(1000)\n",
    "X_test = X_test.sample(10000)              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2b3a0e-3103-47e1-b1f5-13968cda5fd5",
   "metadata": {},
   "source": [
    "# Evidently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8e0a83d-0cf6-411e-a3a7-9f356a629a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: evidently in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (0.2.8)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from evidently) (2.28.2)\n",
      "Requirement already satisfied: pandas>=1.3.5 in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from evidently) (1.4.2)\n",
      "Requirement already satisfied: statsmodels>=0.12.2 in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from evidently) (0.13.2)\n",
      "Requirement already satisfied: pydantic<2 in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from evidently) (1.10.7)\n",
      "Requirement already satisfied: nltk>=3.6.7 in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from evidently) (3.8.1)\n",
      "Requirement already satisfied: scikit-learn>=0.24.0 in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from evidently) (1.1.1)\n",
      "Requirement already satisfied: PyYAML>=5.1 in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from evidently) (6.0)\n",
      "Requirement already satisfied: scipy>=1.5.4 in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from evidently) (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from evidently) (1.22.3)\n",
      "Requirement already satisfied: plotly>=5.5.0 in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from evidently) (5.14.0)\n",
      "Requirement already satisfied: click in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from nltk>=3.6.7->evidently) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from nltk>=3.6.7->evidently) (1.2.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from nltk>=3.6.7->evidently) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from nltk>=3.6.7->evidently) (2023.3.23)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from pandas>=1.3.5->evidently) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from pandas>=1.3.5->evidently) (2.8.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from plotly>=5.5.0->evidently) (21.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from plotly>=5.5.0->evidently) (8.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from pydantic<2->evidently) (4.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from requests>=2.19.0->evidently) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from requests>=2.19.0->evidently) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from requests>=2.19.0->evidently) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from requests>=2.19.0->evidently) (1.26.9)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn>=0.24.0->evidently) (3.1.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from statsmodels>=0.12.2->evidently) (0.5.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from packaging->plotly>=5.5.0->evidently) (3.0.7)\n",
      "Requirement already satisfied: six in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from patsy>=0.5.2->statsmodels>=0.12.2->evidently) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hugues\\appdata\\roaming\\python\\python310\\site-packages (from click->nltk>=3.6.7->evidently) (0.4.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install evidently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbbf867f-5b17-4b38-b6a2-0c19b808aa85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "analyzers are deprecated, use metrics instead\n",
      "dashboards are deprecated, use metrics instead\n"
     ]
    }
   ],
   "source": [
    "from evidently.dashboard import Dashboard\n",
    "from evidently.test_suite import TestSuite\n",
    "from evidently.metric_preset import DataDriftPreset, TargetDriftPreset\n",
    "\n",
    "from evidently.metric_preset import DataDriftPreset, TargetDriftPreset, DataQualityPreset, RegressionPreset\n",
    "from evidently.report import Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81c778c6-f097-4033-82db-021fa7e77cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evidently.dashboard.tabs"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f686ba3c-e69f-46e3-9df5-08aa33ca252d",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from evidently.dashboard import Dashboard\n",
    "from evidently.tabs import DataDriftTab\n",
    "\n",
    "# create an instance of the datadrift tab\n",
    "data_drift_tab = DataDriftTab(\n",
    "    reference_data=X_train,\n",
    "    current_data=X_test,\n",
    "    column_mapping=None\n",
    ")\n",
    "\n",
    "# create a dashboard and add the datadrift tab\n",
    "dashboard = Dashboard(tabs=[data_drift_tab])\n",
    "\n",
    "# generate the datadrift report\n",
    "dashboard.save(\"path/to/output/report.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b3269ec-de0b-42d6-ae6f-cec6cd05b982",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from evidently.dashboard import Dashboard\n",
    "from evidently.dashboard.tabs import DataDriftTab\n",
    "from evidently.test_suite import TestSuite\n",
    "from evidently.test_preset import DataStabilityTestPreset\n",
    "from evidently.test_preset import DataDriftTestPreset\n",
    "from evidently.report import Report\n",
    "from evidently.metric_preset import DataDriftPreset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f70f43d-1a3d-4330-8546-4d4debab37c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stability= TestSuite(tests=[\n",
    "    DataStabilityTestPreset(),\n",
    "])\n",
    "data_stability.run(current_data=X_test, reference_data=X_train, column_mapping=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "717826ca-0ca3-4fa8-a0dc-6f961ed6244e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stability.save_html('DataStability_1704.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc657d94-a6ce-4caf-a1c1-61a0eee69c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hugues\\AppData\\Roaming\\Python\\Python310\\site-packages\\scipy\\stats\\_stats_py.py:6766: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in true_divide\n",
      "\n",
      "C:\\Users\\Hugues\\AppData\\Roaming\\Python\\Python310\\site-packages\\scipy\\stats\\_stats_py.py:6766: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in true_divide\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from evidently.dashboard import Dashboard  \n",
    "from evidently.dashboard.tabs import DataDriftTab\n",
    "data_drift_dashboard = Dashboard(tabs=[DataDriftTab()])\n",
    "data_drift_dashboard.calculate(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40f15fcb-0b6a-4fbc-bd9a-73eaaae69c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_drift_dashboard.save('Data_drift_dashboard_1704.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "433df0ec-b990-4448-9563-0cc9f4a90fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hugues\\AppData\\Roaming\\Python\\Python310\\site-packages\\scipy\\stats\\_stats_py.py:6766: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in true_divide\n",
      "\n",
      "C:\\Users\\Hugues\\AppData\\Roaming\\Python\\Python310\\site-packages\\scipy\\stats\\_stats_py.py:6766: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in true_divide\n",
      "\n",
      "C:\\Users\\Hugues\\AppData\\Roaming\\Python\\Python310\\site-packages\\scipy\\stats\\_stats_py.py:6766: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in true_divide\n",
      "\n",
      "C:\\Users\\Hugues\\AppData\\Roaming\\Python\\Python310\\site-packages\\scipy\\stats\\_stats_py.py:6766: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in true_divide\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_drift= TestSuite(tests=[\n",
    "    DataDriftTestPreset(),\n",
    "])\n",
    "data_drift.run(current_data=X_test, reference_data=X_train, column_mapping=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17af2524-8fe8-4192-9fe8-31623d9f303a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print (report) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96096ecd-aa88-482f-9a08-fcc34a86120e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test_name, test_result \u001b[38;5;129;01min\u001b[39;00m \u001b[43mreport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m():\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_result\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "for test_name, test_result in report.items():\n",
    "    print(f'{test_name}: {test_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3153a8-7bde-48a5-b96c-dec1db25d2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449e9893-83e0-456c-940f-6bf1b659afa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61c6170-37e6-4796-9451-13dfa273e148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60826c55-b3ef-4b21-8603-52f0a413ecf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf65257-9e3e-442b-a0d0-63d0df375ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd34cdeb-462c-44c8-a63b-6054d5c48053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f705860-f252-4963-8625-dfbb1e42c5e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c046df4-7168-49a7-a6e6-3102120f1f2b",
   "metadata": {
    "executionInfo": {
     "elapsed": 72,
     "status": "aborted",
     "timestamp": 1679413603343,
     "user": {
      "displayName": "Hugues Hansen",
      "userId": "06507793026638313555"
     },
     "user_tz": -60
    },
    "id": "2c046df4-7168-49a7-a6e6-3102120f1f2b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f986e7b-cf7a-4c08-82e5-e38482157c34",
   "metadata": {
    "executionInfo": {
     "elapsed": 75,
     "status": "aborted",
     "timestamp": 1679413603347,
     "user": {
      "displayName": "Hugues Hansen",
      "userId": "06507793026638313555"
     },
     "user_tz": -60
    },
    "id": "1f986e7b-cf7a-4c08-82e5-e38482157c34"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec6517a-2d8a-4715-bc12-eb8f493afb7e",
   "metadata": {
    "executionInfo": {
     "elapsed": 73,
     "status": "aborted",
     "timestamp": 1679413603351,
     "user": {
      "displayName": "Hugues Hansen",
      "userId": "06507793026638313555"
     },
     "user_tz": -60
    },
    "id": "7ec6517a-2d8a-4715-bc12-eb8f493afb7e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfef616-93b3-4667-aac8-eae2fc085d8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579b7c93-dcc4-4c4f-9949-5c9de82c4b50",
   "metadata": {
    "executionInfo": {
     "elapsed": 86,
     "status": "aborted",
     "timestamp": 1679413603378,
     "user": {
      "displayName": "Hugues Hansen",
      "userId": "06507793026638313555"
     },
     "user_tz": -60
    },
    "id": "579b7c93-dcc4-4c4f-9949-5c9de82c4b50"
   },
   "outputs": [],
   "source": [
    "algos = [ LogisticRegression(random_state=22),DecisionTreeClassifier(random_state=22), RandomForestClassifier(random_state=22), XGBClassifier(random_state=22), GaussianNB(),DummyClassifier()]\n",
    "\n",
    "# Définir une grille de paramètres à optimiser pour chaque algorithme\n",
    "params = [\n",
    "    \n",
    "    {\"C\": [0.01, 0.1, 1, 10], \"penalty\": [\"l1\", \"l2\", \"elasticnet\", None]}, # pour LogisticRegression ‘l1’, ‘l2’, ‘elasticnet’, None\n",
    "    {\"max_depth\": [3, 5, 7], \"min_samples_leaf\": [5, 10, 15]}, # pour DecisionTreeClassifier\n",
    "    {\"n_estimators\": [100, 200], \"max_depth\": [3, 5]}, # pour RandomForestClassifier \n",
    "    {\"n_estimators\": [100, 200], \"learning_rate\": [0.01, 0.1]}, # pour XGBClassifier \n",
    "    {} ,# pas de paramètres à optimiser pour GaussianNB \n",
    "    {\"strategy\": [\"most_frequent\",\"prior\",\"stratified\",\"uniform\"]}, # pour DummyClassifier\n",
    "]\n",
    "\n",
    "cvi =2\n",
    "scorer = \"roc_auc\"\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Apply oversampling\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train,y_train)\n",
    "\n",
    "\n",
    "comp_algos(X_resampled,y_resampled,X_test,y_test,algos,params,cvi,scorer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e6f795-5aa2-40a1-ae90-38aa95808843",
   "metadata": {
    "executionInfo": {
     "elapsed": 86,
     "status": "aborted",
     "timestamp": 1679413603379,
     "user": {
      "displayName": "Hugues Hansen",
      "userId": "06507793026638313555"
     },
     "user_tz": -60
    },
    "id": "c2e6f795-5aa2-40a1-ae90-38aa95808843"
   },
   "outputs": [],
   "source": [
    "algos = [ LogisticRegression(random_state=22),DecisionTreeClassifier(random_state=22), RandomForestClassifier(random_state=22), XGBClassifier(random_state=22), GaussianNB(),DummyClassifier()]\n",
    "\n",
    "# Définir une grille de paramètres à optimiser pour chaque algorithme\n",
    "params = [\n",
    "    \n",
    "    {\"C\": [0.01, 0.1, 1, 10], \"penalty\": [\"l1\", \"l2\", \"elasticnet\", None]}, # pour LogisticRegression ‘l1’, ‘l2’, ‘elasticnet’, None\n",
    "    {\"max_depth\": [3, 5, 7], \"min_samples_leaf\": [5, 10, 15]}, # pour DecisionTreeClassifier\n",
    "    {\"n_estimators\": [100, 200], \"max_depth\": [3, 5]}, # pour RandomForestClassifier \n",
    "    {\"n_estimators\": [100, 200], \"learning_rate\": [0.01, 0.1]}, # pour XGBClassifier \n",
    "    {} ,# pas de paramètres à optimiser pour GaussianNB \n",
    "    {\"strategy\": [\"most_frequent\",\"prior\",\"stratified\",\"uniform\"]}, # pour DummyClassifier\n",
    "]\n",
    "\n",
    "cvi =2\n",
    "\n",
    "def custom_score_func(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    score = tp + tn - fp -( 10 * fn)\n",
    "    #score 2 tp + (10 * tn )- fp -(10 * fn)\n",
    "    return score\n",
    "\n",
    "# Création du scorer personnalisé\n",
    "scorer = make_scorer(custom_score_func)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Apply oversampling\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train,y_train)\n",
    "\n",
    "\n",
    "#comp_algos(X_resampled,y_resampled,X_test,y_test,algos,params,cvi,scorer)\n",
    "comp_algos(X,y,algos,params,cvi,scorer,sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ff538f-6d2c-4ee1-b4b5-6e39ba985196",
   "metadata": {
    "executionInfo": {
     "elapsed": 86,
     "status": "aborted",
     "timestamp": 1679413603379,
     "user": {
      "displayName": "Hugues Hansen",
      "userId": "06507793026638313555"
     },
     "user_tz": -60
    },
    "id": "56ff538f-6d2c-4ee1-b4b5-6e39ba985196"
   },
   "outputs": [],
   "source": [
    "algos = [ LogisticRegression(random_state=22),DecisionTreeClassifier(random_state=22), RandomForestClassifier(random_state=22), XGBClassifier(random_state=22), GaussianNB(),DummyClassifier()]\n",
    "\n",
    "# Définir une grille de paramètres à optimiser pour chaque algorithme\n",
    "params = [\n",
    "    \n",
    "    {\"C\": [0.01, 0.1, 1, 10], \"penalty\": [\"l1\", \"l2\", \"elasticnet\", None]}, # pour LogisticRegression ‘l1’, ‘l2’, ‘elasticnet’, None\n",
    "    {\"max_depth\": [3, 5, 7], \"min_samples_leaf\": [5, 10, 15]}, # pour DecisionTreeClassifier\n",
    "    {\"n_estimators\": [100, 200], \"max_depth\": [3, 5]}, # pour RandomForestClassifier \n",
    "    {\"n_estimators\": [100, 200], \"learning_rate\": [0.01, 0.1]}, # pour XGBClassifier \n",
    "    {} ,# pas de paramètres à optimiser pour GaussianNB \n",
    "    {\"strategy\": [\"most_frequent\",\"prior\",\"stratified\",\"uniform\"]}, # pour DummyClassifier\n",
    "]\n",
    "\n",
    "cvi =2\n",
    "scorer = \"roc_auc\"\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Apply undersampling\n",
    "rus = RandomUnderSampler(random_state=22)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train,y_train)\n",
    "\n",
    "\n",
    "comp_algos(X_resampled,y_resampled,X_test,y_test,algos,params,cvi,scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cef0891-91a3-42f3-b00e-230805c47828",
   "metadata": {
    "executionInfo": {
     "elapsed": 86,
     "status": "aborted",
     "timestamp": 1679413603379,
     "user": {
      "displayName": "Hugues Hansen",
      "userId": "06507793026638313555"
     },
     "user_tz": -60
    },
    "id": "5cef0891-91a3-42f3-b00e-230805c47828"
   },
   "outputs": [],
   "source": [
    "algos = [ LogisticRegression(random_state=22),DecisionTreeClassifier(random_state=22), RandomForestClassifier(random_state=22), XGBClassifier(random_state=22), GaussianNB(),DummyClassifier()]\n",
    "\n",
    "# Définir une grille de paramètres à optimiser pour chaque algorithme\n",
    "params = [\n",
    "    \n",
    "    {\"C\": [0.01, 0.1, 1, 10], \"penalty\": [\"l1\", \"l2\", \"elasticnet\", None]}, # pour LogisticRegression ‘l1’, ‘l2’, ‘elasticnet’, None\n",
    "    {\"max_depth\": [3, 5, 7], \"min_samples_leaf\": [5, 10, 15]}, # pour DecisionTreeClassifier\n",
    "    {\"n_estimators\": [100, 200], \"max_depth\": [3, 5]}, # pour RandomForestClassifier \n",
    "    {\"n_estimators\": [100, 200], \"learning_rate\": [0.01, 0.1]}, # pour XGBClassifier \n",
    "    {} ,# pas de paramètres à optimiser pour GaussianNB \n",
    "    {\"strategy\": [\"most_frequent\",\"prior\",\"stratified\",\"uniform\"]}, # pour DummyClassifier\n",
    "]\n",
    "\n",
    "cvi =2\n",
    "\n",
    "def custom_score_func(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    score = tp + tn - fp -( 10 * fn)\n",
    "    #score 2 tp + (10 * tn )- fp -(10 * fn)\n",
    "    return score\n",
    "\n",
    "# Création du scorer personnalisé\n",
    "scorer = make_scorer(custom_score_func)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Apply undersampling\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train,y_train)\n",
    "\n",
    "\n",
    "comp_algos(X_resampled,y_resampled,X_test,y_test,algos,params,cvi,scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302bb835-3868-4ec9-8165-689997bd54d0",
   "metadata": {
    "executionInfo": {
     "elapsed": 87,
     "status": "aborted",
     "timestamp": 1679413603380,
     "user": {
      "displayName": "Hugues Hansen",
      "userId": "06507793026638313555"
     },
     "user_tz": -60
    },
    "id": "302bb835-3868-4ec9-8165-689997bd54d0"
   },
   "outputs": [],
   "source": [
    "algos = [ LogisticRegression(random_state=22),DecisionTreeClassifier(random_state=22), RandomForestClassifier(random_state=22), XGBClassifier(random_state=22), GaussianNB(),DummyClassifier()]\n",
    "\n",
    "# Définir une grille de paramètres à optimiser pour chaque algorithme\n",
    "params = [\n",
    "    \n",
    "    {\"C\": [0.01, 0.1, 1, 10], \"penalty\": [\"l1\", \"l2\", \"elasticnet\", None]}, # pour LogisticRegression ‘l1’, ‘l2’, ‘elasticnet’, None\n",
    "    {\"max_depth\": [3, 5, 7], \"min_samples_leaf\": [5, 10, 15]}, # pour DecisionTreeClassifier\n",
    "    {\"n_estimators\": [100, 200], \"max_depth\": [3, 5]}, # pour RandomForestClassifier \n",
    "    {\"n_estimators\": [100, 200], \"learning_rate\": [0.01, 0.1]}, # pour XGBClassifier \n",
    "    {} ,# pas de paramètres à optimiser pour GaussianNB \n",
    "    {\"strategy\": [\"most_frequent\",\"prior\",\"stratified\",\"uniform\"]}, # pour DummyClassifier\n",
    "]\n",
    "\n",
    "cvi =2\n",
    "scorer = \"roc_auc\"\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTETomek(random_state=0)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train,y_train)\n",
    "\n",
    "comp_algos(X_resampled,y_resampled,X_test,y_test,algos,params,cvi,scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuavIJmpBiU0",
   "metadata": {
    "executionInfo": {
     "elapsed": 87,
     "status": "aborted",
     "timestamp": 1679413603380,
     "user": {
      "displayName": "Hugues Hansen",
      "userId": "06507793026638313555"
     },
     "user_tz": -60
    },
    "id": "nuavIJmpBiU0"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5e6c82-1e18-4cea-97ea-e5989ad29c2b",
   "metadata": {
    "executionInfo": {
     "elapsed": 86,
     "status": "aborted",
     "timestamp": 1679413603380,
     "user": {
      "displayName": "Hugues Hansen",
      "userId": "06507793026638313555"
     },
     "user_tz": -60
    },
    "id": "0b5e6c82-1e18-4cea-97ea-e5989ad29c2b"
   },
   "outputs": [],
   "source": [
    "algos = [ LogisticRegression(random_state=22),DecisionTreeClassifier(random_state=22), RandomForestClassifier(random_state=22), XGBClassifier(random_state=22), GaussianNB(),DummyClassifier()]\n",
    "\n",
    "# Définir une grille de paramètres à optimiser pour chaque algorithme\n",
    "params = [\n",
    "    \n",
    "    {\"C\": [0.01, 0.1, 1, 10], \"penalty\": [\"l1\", \"l2\", \"elasticnet\", None]}, # pour LogisticRegression ‘l1’, ‘l2’, ‘elasticnet’, None\n",
    "    {\"max_depth\": [3, 5, 7], \"min_samples_leaf\": [5, 10, 15]}, # pour DecisionTreeClassifier\n",
    "    {\"n_estimators\": [100, 200], \"max_depth\": [3, 5]}, # pour RandomForestClassifier \n",
    "    {\"n_estimators\": [100, 200], \"learning_rate\": [0.01, 0.1]}, # pour XGBClassifier \n",
    "    {} ,# pas de paramètres à optimiser pour GaussianNB \n",
    "    {\"strategy\": [\"most_frequent\",\"prior\",\"stratified\",\"uniform\"]}, # pour DummyClassifier\n",
    "]\n",
    "\n",
    "cvi =2\n",
    "\n",
    "def custom_score_func(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    score = tp + tn - fp -( 10 * fn)\n",
    "    #score 2 tp + (10 * tn )- fp -(10 * fn)\n",
    "    return score\n",
    "\n",
    "# Création du scorer personnalisé\n",
    "scorer = make_scorer(custom_score_func)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTETomek(random_state=0)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train,y_train)\n",
    "\n",
    "comp_algos(X_resampled,y_resampled,X_test,y_test,algos,params,cvi,scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eed5ddc",
   "metadata": {
    "executionInfo": {
     "elapsed": 87,
     "status": "aborted",
     "timestamp": 1679413603381,
     "user": {
      "displayName": "Hugues Hansen",
      "userId": "06507793026638313555"
     },
     "user_tz": -60
    },
    "id": "5eed5ddc"
   },
   "outputs": [],
   "source": [
    "#LogisticRegression() {'C': 1, 'penalty': 'l2'} \n",
    "grid = GridSearchCV(estimator=algos[i], param_grid=params[i], scoring=\"roc_auc\", cv=3, refit= True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a51e6a-2856-4e9e-bd86-642e0a5b73ae",
   "metadata": {
    "executionInfo": {
     "elapsed": 87,
     "status": "aborted",
     "timestamp": 1679413603381,
     "user": {
      "displayName": "Hugues Hansen",
      "userId": "06507793026638313555"
     },
     "user_tz": -60
    },
    "id": "28a51e6a-2856-4e9e-bd86-642e0a5b73ae"
   },
   "outputs": [],
   "source": [
    "\n",
    "nsplit = 3\n",
    "    \n",
    "    \n",
    "debut = time.time()\n",
    "\n",
    "\n",
    "\n",
    "estimator = DecisionTreeClassifier(max_depth=7, min_samples_leaf=15)\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])  \n",
    "\n",
    "clf = Pipeline(steps=[ #('preprocessor', numeric_transformer),\n",
    "                      ('estimator', estimator) ])\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=nsplit, shuffle=True,random_state=22 ) \n",
    "\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    x_train, x_test = X.iloc[train_index] , X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    clf.fit(x_train, y_train) \n",
    "\n",
    "    \n",
    "#c faire tourner le prédict\n",
    "pred_y = clf.predict(x_test)\n",
    "score = accuracy_score(y_test,pred_y)\n",
    "print ('accuracy test ',score)\n",
    "roc_auc = roc_auc_score(y_test, pred_y)\n",
    "print ( 'roc_auc_  test ',roc_auc)\n",
    "\n",
    "\n",
    "pred_y_train = clf.predict(x_train)\n",
    "score = accuracy_score(y_train,pred_y_train)\n",
    "print ('accuracy train ',score)\n",
    "roc_auc = roc_auc_score(y_train, pred_y_train)\n",
    "print ( 'roc_auc_  train ',roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3882307b-7b1d-4e11-82a9-36be14d5080b",
   "metadata": {
    "executionInfo": {
     "elapsed": 88,
     "status": "aborted",
     "timestamp": 1679413603382,
     "user": {
      "displayName": "Hugues Hansen",
      "userId": "06507793026638313555"
     },
     "user_tz": -60
    },
    "id": "3882307b-7b1d-4e11-82a9-36be14d5080b"
   },
   "outputs": [],
   "source": [
    "\n",
    "nsplit = 3\n",
    "    \n",
    "    \n",
    "debut = time.time()\n",
    "\n",
    "grid = GridSearchCV(estimator=DecisionTreeClassifier(), \n",
    "                                param_grid={\"max_depth\": [3, 5, 7], \"min_samples_leaf\": [5, 10, 15]}, scoring=\"roc_auc\", cv=3, refit= True )\n",
    "\n",
    "\n",
    "grid.fit(X,y)\n",
    "\n",
    "# Afficher le meilleur score et le meilleur algorithme trouvé par GridSearchCV \n",
    "print(\"Meilleur score:\", grid.best_score_)\n",
    "print(\"Meilleur algorithme:\", grid.best_estimator_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0feedb-7485-4429-8b55-412f9b56a498",
   "metadata": {
    "executionInfo": {
     "elapsed": 88,
     "status": "aborted",
     "timestamp": 1679413603382,
     "user": {
      "displayName": "Hugues Hansen",
      "userId": "06507793026638313555"
     },
     "user_tz": -60
    },
    "id": "1d0feedb-7485-4429-8b55-412f9b56a498"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Fit GridSearchCV on training data\n",
    "grid = GridSearchCV(estimator=DecisionTreeClassifier(), \n",
    "                    param_grid={\"max_depth\": [3, 5, 7], \"min_samples_leaf\": [5, 10, 15]}, \n",
    "                    scoring=\"roc_auc\", cv=3)\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "# Make predictions on test data using best_estimator_\n",
    "y_pred = grid.best_estimator_.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Calculate FPR and TPR\n",
    "fpr, tpr, thresholds = roc_curve(y_test,y_pred)\n",
    "\n",
    "# Calculate AUC\n",
    "roc_auc = auc(fpr,tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot(fpr,tpr,label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20acdf2-d4b2-400e-9a95-005beb58c404",
   "metadata": {
    "executionInfo": {
     "elapsed": 88,
     "status": "aborted",
     "timestamp": 1679413603382,
     "user": {
      "displayName": "Hugues Hansen",
      "userId": "06507793026638313555"
     },
     "user_tz": -60
    },
    "id": "e20acdf2-d4b2-400e-9a95-005beb58c404"
   },
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=DecisionTreeClassifier, param_grid={\"max_depth\": [3, 5, 7], \"min_samples_leaf\": [5, 10, 15]}, scoring=\"roc_auc\", cv=3, refit= True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c2486c-371d-4dbb-86e8-3f49ac61f9ad",
   "metadata": {
    "executionInfo": {
     "elapsed": 88,
     "status": "aborted",
     "timestamp": 1679413603382,
     "user": {
      "displayName": "Hugues Hansen",
      "userId": "06507793026638313555"
     },
     "user_tz": -60
    },
    "id": "73c2486c-371d-4dbb-86e8-3f49ac61f9ad"
   },
   "outputs": [],
   "source": [
    "\n",
    "      \n",
    "    \n",
    "    \n",
    "    \n",
    "\"\"\" Append= pd.DataFrame([['RandomForest' , \n",
    "                        np.around (mean_squared_error(y_test,reg.predict(x_test)),3),\n",
    "                       np.around (mean_squared_error(y_test,reg.predict(x_test),squared=False),3),\n",
    "                      np.around(r2_score(y_test,reg.predict(x_test)),3),\n",
    "                     np.around( mean_absolute_percentage_error(y_test,reg.predict(x_test)),3),\n",
    "                      np.around(r2_score(y_train,reg.predict(x_train)),3) ,\n",
    "                      time.time() - debut]], \n",
    "                     columns=['méthode', 'MSE','RMSE','R2 Test','MA%E','R2 Train','Durée'])\n",
    "    \n",
    "\n",
    "Report = pd.concat([Report, Append]) \n",
    "Report\"\"\" \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66672f1-cffd-418e-818b-fb4cdd4cb02d",
   "metadata": {
    "executionInfo": {
     "elapsed": 88,
     "status": "aborted",
     "timestamp": 1679413603382,
     "user": {
      "displayName": "Hugues Hansen",
      "userId": "06507793026638313555"
     },
     "user_tz": -60
    },
    "id": "d66672f1-cffd-418e-818b-fb4cdd4cb02d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0e628a",
   "metadata": {
    "executionInfo": {
     "elapsed": 88,
     "status": "aborted",
     "timestamp": 1679413603383,
     "user": {
      "displayName": "Hugues Hansen",
      "userId": "06507793026638313555"
     },
     "user_tz": -60
    },
    "id": "6a0e628a"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Calculer le score roc_auc pour chaque algorithme \n",
    "    roc_aucs = []\n",
    "    for i in range(len(algos)):\n",
    "        roc_aucs.append(roc_auc_score(y_true=y,y_score=probas[:,i]))\n",
    "\n",
    "# Créer un dataframe pandas qui contient les scores roc_auc de chaque algorithme \n",
    "    roc_df = pd.DataFrame({\"Algorithme\": algos,\"ROC_AUC\": roc_aucs})\n",
    "    print(roc_df)\n",
    "\n",
    "# Prédire les classes pour chaque algorithme \n",
    "    preds = grid.predict(X)\n",
    "\n",
    "# Calculer la matrice de confusion pour chaque algorithme \n",
    "    confusions = []\n",
    "    for i in range(len(algos)):\n",
    "        confusions.append(confusion_matrix(y_true=y,y_pred=preds[:,i]))\n",
    "\n",
    "# Créer un dataframe pandas qui contient les matrices de confusion de chaque algorithme \n",
    "    conf_df = pd.DataFrame({\"Algorithme\": algos,\"Confusion Matrix\": confusions})\n",
    "    print(conf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3e7505",
   "metadata": {
    "executionInfo": {
     "elapsed": 88,
     "status": "aborted",
     "timestamp": 1679413603383,
     "user": {
      "displayName": "Hugues Hansen",
      "userId": "06507793026638313555"
     },
     "user_tz": -60
    },
    "id": "ea3e7505"
   },
   "outputs": [],
   "source": [
    "# Importer la bibliothèque Keras Tuner qui permet de faire de l'optimisation bayésienne\n",
    "from kerastuner.tuners import BayesianOptimization\n",
    "\n",
    "# Définir une fonction qui crée un modèle de classification naïve bayésienne avec des hyperparamètres à optimiser\n",
    "def build_model(hp):\n",
    "    # Créer un objet GaussianNB \n",
    "    model = GaussianNB()\n",
    "    # Définir les hyperparamètres à optimiser: le lissage de Laplace (var_smoothing) et le seuil de décision (threshold)\n",
    "    hp_var_smoothing = hp.Float('var_smoothing', 1e-9, 1e-3, sampling='log')\n",
    "    hp_threshold = hp.Float('threshold', 0.0, 1.0)\n",
    "    # Affecter les valeurs des hyperparamètres au modèle \n",
    "    model.var_smoothing = hp_var_smoothing\n",
    "    model.threshold = hp_threshold\n",
    "    # Retourner le modèle \n",
    "    return model\n",
    "\n",
    "# Créer un objet BayesianOptimization qui va comparer les performances du modèle sur les données en utilisant le score roc_auc comme critère d'évaluation \n",
    "tuner = BayesianOptimization(build_model,\n",
    "                             objective='roc_auc',\n",
    "                             max_trials=10,\n",
    "                             executions_per_trial=1)\n",
    "\n",
    "# Lancer la recherche des meilleurs hyperparamètres pour le modèle \n",
    "tuner.search(X,y)\n",
    "\n",
    "# Afficher les meilleurs hyperparamètres trouvés par BayesianOptimization \n",
    "print(\"Meilleurs hyperparamètres:\", tuner.get_best_hyperparameters()[0].values)\n",
    "\n",
    "# Prédire les probabilités des classes pour le modèle optimisé \n",
    "proba_bayes = tuner.predict(X)\n",
    "\n",
    "# Calculer le score roc_auc pour le modèle optimisé \n",
    "roc_auc_bayes = roc_auc_score(y_true=y,y_score=proba_bayes)\n",
    "\n",
    "# Ajouter le score roc_auc du modèle optimisé au dataframe pandas qui contient les scores roc_auc de chaque algorithme \n",
    "roc_df.loc[len(roc_df)] = [\"GaussianNB Optimized\", roc_auc_bayes]\n",
    "print(roc_df)\n",
    "\n",
    "# Prédire les classes pour le modèle optimisé \n",
    "pred_bayes = tuner.predict_classes(X)\n",
    "\n",
    "# Calculer la matrice de confusion pour le modèle optimisé \n",
    "confusion_bayes = confusion_matrix(y_true=y,y_pred=pred_bayes)\n",
    "\n",
    "# Ajouter la matrice de confusion du modèle optimisé au dataframe pandas qui contient les matrices de confusion de chaque algorithme \n",
    "conf_df.loc[len(conf_df)] = [\"GaussianNB Optimized\", confusion_bayes]\n",
    "print(conf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce81002",
   "metadata": {
    "executionInfo": {
     "elapsed": 88,
     "status": "aborted",
     "timestamp": 1679413603383,
     "user": {
      "displayName": "Hugues Hansen",
      "userId": "06507793026638313555"
     },
     "user_tz": -60
    },
    "id": "2ce81002"
   },
   "outputs": [],
   "source": [
    "# Importer la bibliothèque matplotlib.pyplot qui permet de faire des graphiques \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Créer une figure avec une taille de 10x10 pouces \n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "# Parcourir chaque algorithme dans le dataframe roc_df qui contient les scores roc_auc de chaque algorithme \n",
    "for index, row in roc_df.iterrows():\n",
    "    # Récupérer le nom de l'algorithme et le score roc_auc \n",
    "    algo = row[\"Algo\"]\n",
    "    score = row[\"ROC_AUC\"]\n",
    "    # Calculer les taux de faux positifs (fpr) et de vrais positifs (tpr) en utilisant la fonction roc_curve de sklearn.metrics \n",
    "    fpr, tpr, thresholds = roc_curve(y_true=y,y_score=proba_dict[algo])\n",
    "    # Tracer la courbe ROC en utilisant la fonction plot de matplotlib.pyplot \n",
    "    plt.plot(fpr,tpr,label=f\"{algo} (AUC={score:.3f})\")\n",
    "\n",
    "# Ajouter un titre au graphique \n",
    "plt.title(\"Courbes ROC des différents algorithmes\")\n",
    "\n",
    "# Ajouter des légendes aux axes x et y \n",
    "plt.xlabel(\"Taux de faux positifs\")\n",
    "plt.ylabel(\"Taux de vrais positifs\")\n",
    "\n",
    "# Ajouter une grille au graphique pour faciliter la lecture \n",
    "plt.grid()\n",
    "\n",
    "# Ajouter une ligne diagonale qui représente un classifieur aléatoire \n",
    "plt.plot([0,1],[0,1],linestyle=\"--\",color=\"black\",label=\"Aléatoire\")\n",
    "\n",
    "# Ajouter une légende au graphique pour identifier chaque courbe ROC \n",
    "plt.legend()\n",
    "\n",
    "# Afficher le graphique à l'écran \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a229cb5",
   "metadata": {
    "id": "3a229cb5"
   },
   "source": [
    "Les courbes ROC permettent d’évaluer les performances d’un modèle de classification en fonction du seuil de décision choisi. Elles représentent le taux de vrais positifs (TPR) en fonction du taux de faux positifs (FPR) pour différents seuils. Plus la courbe est proche du coin supérieur gauche du graphique, plus le modèle est performant. L’aire sous la courbe (AUC) est une mesure synthétique qui résume la qualité d’un modèle: plus elle est proche de 1, mieux c’est.\n",
    "\n",
    "Sur ce graphique, on peut voir que le modèle optimisé par l’optimisation bayésienne a la meilleure performance parmi tous les modèles testés. Il a une AUC élevée et il domine les autres courbes sur tout l’intervalle des FPR. Cela signifie qu’il a un bon compromis entre sensibilité et spécificité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91799052",
   "metadata": {
    "executionInfo": {
     "elapsed": 89,
     "status": "aborted",
     "timestamp": 1679413603384,
     "user": {
      "displayName": "Hugues Hansen",
      "userId": "06507793026638313555"
     },
     "user_tz": -60
    },
    "id": "91799052"
   },
   "outputs": [],
   "source": [
    "# Importer les bibliothèques nécessaires\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "import pandas as pd\n",
    "\n",
    "# Créer un dataframe pandas avec les étiquettes réelles et les probabilités prédites\n",
    "y_true = [0, 0, 0, 1, 1, 1]\n",
    "y_pred = [0.1, 0.2, 0.3, 0.7, 0.8, 0.9]\n",
    "df = pd.DataFrame({\"y_true\": y_true,\"y_pred\": y_pred})\n",
    "\n",
    "# Calculer les taux de faux positifs et de vrais positifs pour chaque classe\n",
    "fpr_0,tpr_0,_ = roc_curve(y_true=df[\"y_true\"],y_score=1-df[\"y_pred\"],pos_label=0)\n",
    "fpr_1,tpr_1,_ = roc_curve(y_true=df[\"y_true\"],y_score=df[\"y_pred\"],pos_label=1)\n",
    "\n",
    "# Créer un objet FacetGrid avec seaborn\n",
    "g = sns.FacetGrid(df,hue=\"y_true\",height=5)\n",
    "\n",
    "# Appliquer la fonction plot à chaque sous-graphique avec la méthode map\n",
    "g.map(plt.plot,fpr_0,tpr_0,label=\"Classe 0\")\n",
    "g.map(plt.plot,fpr_1,tpr_1,label=\"Classe 1\")\n",
    "\n",
    "# Ajouter des titres, des légendes et des annotations au graphique\n",
    "g.set_axis_labels(\"Taux de faux positifs\",\"Taux de vrais positifs\")\n",
    "g.fig.suptitle(\"Courbes ROC avec seaborn\")\n",
    "g.add_legend()\n",
    "plt.plot([0,1],[0,1],linestyle=\"--\",color=\"black\",label=\"Aléatoire\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e80281-1b69-425a-a73a-191c23fcdc9b",
   "metadata": {
    "id": "f5e80281-1b69-425a-a73a-191c23fcdc9b"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1Jt7PiO9zRBoNGlNKSwcQjEsl9iIAL951",
     "timestamp": 1679311336338
    },
    {
     "file_id": "1SGZ4mvrsrO3TDJ09fHbiDpTiAaYwFevg",
     "timestamp": 1679307281408
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
