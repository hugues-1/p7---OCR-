{"cells":[{"cell_type":"markdown","id":"530cc79d-7655-4802-a839-52d871672f83","metadata":{"id":"530cc79d-7655-4802-a839-52d871672f83"},"source":["## ToDo : "]},{"cell_type":"code","execution_count":1,"id":"9f2e5131","metadata":{"id":"9f2e5131","executionInfo":{"status":"ok","timestamp":1679311568740,"user_tz":-60,"elapsed":5859,"user":{"displayName":"Hugues Hansen","userId":"06507793026638313555"}}},"outputs":[],"source":["# Importer les bibliothèques nécessaires\n","\n","import pandas as pd\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.dummy import DummyClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from xgboost import XGBClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.metrics import roc_auc_score, confusion_matrix,accuracy_score\n","import numpy as np\n","import pandas as pd\n","import gc\n","import time\n","from contextlib import contextmanager\n","import lightgbm as lgb\n","from lightgbm import LGBMClassifier\n","from sklearn.metrics import roc_auc_score, roc_curve\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.ensemble import HistGradientBoostingClassifier\n","from sklearn.model_selection import KFold, StratifiedKFold\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","import missingno as msno\n","import numpy as np\n","from sklearn.impute import SimpleImputer\n","from sklearn.experimental import enable_iterative_imputer\n","from sklearn.impute import IterativeImputer\n","from sklearn.impute import KNNImputer\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import ConfusionMatrixDisplay\n","import seaborn as sns\n","import imblearn as imb\n","from imblearn.over_sampling import RandomOverSampler\n","from imblearn.under_sampling import RandomUnderSampler\n","from imblearn.combine import SMOTETomek\n","from sklearn.metrics import auc\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import make_scorer\n","from imblearn import FunctionSampler\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.pipeline import Pipeline"]},{"cell_type":"code","execution_count":2,"id":"fe044698","metadata":{"id":"fe044698","executionInfo":{"status":"ok","timestamp":1679311593534,"user_tz":-60,"elapsed":24800,"user":{"displayName":"Hugues Hansen","userId":"06507793026638313555"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b91a6fe8-9cb4-40ce-9ce4-699c92d64e87"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting shap\n","  Downloading shap-0.41.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (572 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m572.4/572.4 KB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from shap) (1.10.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from shap) (1.22.4)\n","Requirement already satisfied: numba in /usr/local/lib/python3.9/dist-packages (from shap) (0.56.4)\n","Collecting slicer==0.0.7\n","  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from shap) (1.4.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from shap) (1.2.2)\n","Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.9/dist-packages (from shap) (23.0)\n","Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.9/dist-packages (from shap) (4.65.0)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.9/dist-packages (from shap) (2.2.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from numba->shap) (63.4.3)\n","Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba->shap) (0.39.1)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->shap) (2022.7.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->shap) (2.8.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->shap) (3.1.0)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->shap) (1.1.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->shap) (1.15.0)\n","Installing collected packages: slicer, shap\n","Successfully installed shap-0.41.0 slicer-0.0.7\n"]}],"source":["!pip install shap\n","import shap"]},{"cell_type":"code","execution_count":null,"id":"a24b06ad","metadata":{"id":"a24b06ad"},"outputs":[],"source":["try:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    base=pd.read_csv(\"/content/drive/MyDrive/Notebooks/P7/basep7.csv\")\n","        \n","except ModuleNotFoundError :\n","    \n","    base = pd.read_csv(\"basep7.csv\")\n","    \n","base = base.drop( columns = ['Unnamed: 0'])"]},{"cell_type":"code","execution_count":null,"id":"9a90ebe0","metadata":{"id":"9a90ebe0"},"outputs":[],"source":["# one_hot_encoder classique pour les non numériques\n","def one_hot_encoder(base, nan_as_category = True):\n","    original_columns = list(base.columns)\n","    categorical_columns = [col for col in base.columns if base[col].dtype == 'object']\n","    base2 = pd.get_dummies(base, columns= categorical_columns, dummy_na= True)\n","    new_columns = [c for c in base.columns if c not in original_columns]\n","    return base2\n","print (base.shape)\n","base2 =one_hot_encoder(base)\n","print (base2.shape)\n","base = base2\n","del base2"]},{"cell_type":"code","execution_count":null,"id":"95b1f4fe-9a96-4d9e-8ed7-fcc2ac13becf","metadata":{"id":"95b1f4fe-9a96-4d9e-8ed7-fcc2ac13becf"},"outputs":[],"source":["# Remplacer les valeurs manquantes par la moyenne de la colonne\n","base = base.fillna(base.mean())"]},{"cell_type":"code","execution_count":null,"id":"7aadae66-a87c-4bc0-b4c5-5bc4001ea36f","metadata":{"id":"7aadae66-a87c-4bc0-b4c5-5bc4001ea36f"},"outputs":[],"source":["# Séparer les variables explicatives (X) et la variable cible (y)\n","X = base.drop(\"TARGET\", axis=1)\n","y = base[\"TARGET\"]\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"2eded73f-1548-4e31-8413-d36c34ead49e","metadata":{"id":"2eded73f-1548-4e31-8413-d36c34ead49e"},"outputs":[],"source":["# scaler \n","col_names=X.select_dtypes(include='number').columns.tolist()\n","features = X[col_names]\n","scaler = StandardScaler().fit(features.values)\n","features_scale = scaler.transform(features.values)\n","X[col_names] = features_scale\n","print (X.shape) \n","del features\n","del features_scale"]},{"cell_type":"code","execution_count":null,"id":"c5e06395-aa30-4107-9c5c-7f783de12ba2","metadata":{"tags":[],"id":"c5e06395-aa30-4107-9c5c-7f783de12ba2"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"e741f79e","metadata":{"id":"e741f79e"},"outputs":[],"source":["# Améliore l'affichage des DataFrame de résultats. \n","pd.set_option('display.max_rows', None)\n","pd.set_option('display.max_columns', None)\n","pd.set_option('display.width', None)\n","pd.set_option('display.max_colwidth', -1)"]},{"cell_type":"markdown","id":"736b6bc1-d2c5-422d-91fc-47c5a36f2f5d","metadata":{"id":"736b6bc1-d2c5-422d-91fc-47c5a36f2f5d"},"source":["# fonction shap\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3ohf4ulLOOIz"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n","X_resampled, y_resampled = RandomUnderSampler(random_state=22).fit_resample(X_train,y_train)\n","# entraînez votre modèle\n","#model = xgboost.train({\"learning_rate\": 0.01}, xgboost.DMatrix(X_train, label=y_train), 100)\n","#model = DecisionTreeClassifier(random_state=22, max_depth = 3, min_samples_leaf = 2)\n","model = RandomForestClassifier(n_estimators=10, random_state=22)\n","model.fit(X_resampled,y_resampled)\n","\n","\n"],"id":"3ohf4ulLOOIz"},{"cell_type":"code","source":["explainer = shap.Explainer(model)"],"metadata":{"id":"LXnIXF3Gw1Qr"},"id":"LXnIXF3Gw1Qr","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# calculate the SHAP values for the first test observation\n","shap_values = explainer(X_test.iloc[[0]])"],"metadata":{"id":"UQ5KhWjBxCuu"},"id":"UQ5KhWjBxCuu","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# display the SHAP values\n","print(\"SHAP values:\")\n","for i in range(X_test.shape[1]):\n","    print(f\"{X_test.columns[i]:<8} SHAP value: {shap_values[0][0][i]:.3f}\")"],"metadata":{"id":"3pk2d-WOxDkR"},"id":"3pk2d-WOxDkR","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# expliquez les prédictions du modèle avec SHAP\n","\n","#shap_values = shap.TrExplainer(model).shap_values(x_train)\n","#classifier = transformers.pipeline('sentiment-analysis', return_all_scores=True)\n","#classifier(short_data[:2])\n","\n","#model.predict_proba(X_train)[:0]\n","\n","\n","\n","\n","shap_values = explainer(X_test)\n","\n","# approximate the interaction values\n","approx_interactions = shap.approximate_interactions(model.predict, X_test, nsamples=100)\n","\n","# visualize the interaction values for the first test observation\n","shap.interaction_plot(0, approx_interactions[0], X_test.iloc[0])\n","\n","\n","# visualize the Shapley values for the first test observation\n","# shap.waterfall_plot(explainer.expected_value[0], shap_values[0][0], X_test.iloc[0])\n","\n","\n","\"\"\"\n","explainer = shap.Explainer(model)\n","shap_values = explainer(X_resampled)\n","\n","# visualisez les valeurs de Shapley pour la première observation de test\n","shap.waterfall_plot(explainer.base_values[0], values[0], X[0])\n","\n","#shap.plots.waterfall(shap_values[0])\n","shap.waterfall_plot(explainer.base_values[0], values[0][0], X[0])\n","\"\"\""],"metadata":{"id":"K9U0aof-YgHS"},"execution_count":null,"outputs":[],"id":"K9U0aof-YgHS"},{"cell_type":"code","source":[],"metadata":{"id":"BLkmti1SxAyC"},"id":"BLkmti1SxAyC","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Z8Ps66XmxBRN"},"id":"Z8Ps66XmxBRN","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qOhcPmFDN8iS"},"id":"qOhcPmFDN8iS","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p84fK13aN94S"},"outputs":[],"source":["\"\"\" reg = RandomForestRegressor(random_state=22,max_depth =7, min_samples_split= 3, min_samples_leaf=1,n_estimators=100)\n","skf = StratifiedKFold(n_splits=5, shuffle=True,random_state=22 )\n","for train_index, test_index in skf.split(X, buildingnr['log_SiteEnergyUse(kBtu)_class']):\n","    x_train_fold, x_test_fold = X.iloc[train_index] , X.iloc[test_index]\n","    y_train_fold, y_test_fold = y[train_index], y[test_index]\n","    reg.fit(x_train_fold, y_train_fold)\n","\n","    import shap\n","shap_values = shap.TreeExplainer(reg).shap_values(x_train_fold)\n","shap.summary_plot(shap_values, x_train_fold, plot_type=\"bar\")\n","\n","explainer = shap.Explainer(reg.predict, x_test_fold)\n","# Calculates the SHAP values - It takes some time\n","shap_values = explainer(x_test_fold)\"\"\""],"id":"p84fK13aN94S"},{"cell_type":"code","execution_count":null,"id":"8843762e","metadata":{"id":"8843762e"},"outputs":[],"source":["def comp_algos(X,y,algos,params,cvi,scorer,sampling) : \n","\n","    \n","    roc_aucs = []\n","    confusions = []\n","    Report_df = pd.DataFrame(columns=['Algorithme', 'score nom ','score']) \n","    Append = []\n","\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) #random_state ? \n","    \n","    # Apply oversampling\n","    #ros = RandomOverSampler(random_state=42)\n","    #X_resampled, y_resampled = sampling.fit_resample(X_train,y_train)\n","    \n","    for i in range(len(algos)): \n","        \n","        #faire boucle sur le sampling \n","        for s in range(len(sampling)): \n","            \n","            # Apply sampling\n","            \n","            debut = time.time()\n","            X_resampled, y_resampled = sampling[s].fit_resample(X_train,y_train)\n","\n","# Créer un objet GridSearchCV qui va comparer les performances des algorithmes sur les données en utilisant le score roc_auc comme critère d'évaluation \n","            print (algos[i], params[i] )\n","    \n","          \n","           \n","            grid = GridSearchCV(estimator=algos[i], param_grid=params[i], scoring=scorer, cv=cvi, refit= True )\n","          \n","            grid.fit(X_resampled,y_resampled)\n","            del X_resampled\n","            del y_resampled\n","\n","# Afficher le meilleur score et le meilleur algorithme trouvé par GridSearchCV \n","            print(\"Meilleur score:\", grid.best_score_)\n","            print(\"Meilleur algorithme:\", grid.best_estimator_)\n","            #print ( \"cv results ;\", grid.cv_results_ ) \n","            print ( \"best_params_\",grid.best_params_)\n","            print (\"best_index_\",grid.best_index_)\n","            print (\"scorer_\",grid.scorer_)\n","            print (\"n_splits_\",grid.n_splits_)\n","            print (\"sampling method\",sampling[s])\n","    \n","            cv_result= pd.DataFrame(grid.cv_results_)\n","            display ( cv_result )\n","\n","# Prédire les classes pour chaque algorithme \n","            pred_y_train = grid.predict(X_train)\n","            score = accuracy_score(y_train,pred_y_train)\n","            print ('accuracy train',score)\n","          \n","            roc_auc_train = roc_auc_score(y_train, pred_y_train)\n","            #print ( 'roc_auc_train',roc_auc_train)\n","            print(f'roc_auc_train: {roc_auc_train:.1%}')\n","\n","            pred_y_train_proba=grid.predict_proba(X_train)[:,1]\n","            roc_auc_discret_train = roc_auc_score(y_train, pred_y_train_proba)\n","            print( \"Roc auc train predict proba\",roc_auc_discret_train)\n","        \n","            pred_y_test = grid.predict(X_test)\n","            score = accuracy_score(y_test,pred_y_test)\n","            print ('accuracy test',score)\n","          \n","            roc_auc_test = roc_auc_score(y_test, pred_y_test)\n","            print ( 'roc_auc_ test ',roc_auc_test)\n","\n","            pred_y_test_proba=grid.predict_proba(X_test)[:,1]\n","            roc_auc_discret_test= roc_auc_score(y_test, pred_y_test_proba)\n","            print( \"Roc auc score test predict proba\",roc_auc_discret_test)\n","\n","# Calculer la matrice de confusion pour chaque algorithme\n","\n","            matrice_confusion = confusion_matrix(y_true=y_train,y_pred=pred_y_train)\n","            tn, fp, fn, tp = confusion_matrix(y_true=y_train,y_pred=pred_y_train, normalize='all').ravel()\n","\n","# Change figure size and increase dpi for better resolution\n","            plt.figure(figsize=(2,1), dpi=100)\n","# Scale up the size of all text\n","            sns.set(font_scale = 1)\n","\n","# Plot Confusion Matrix using Seaborn heatmap()\n","# Parameters:\n","# first param - confusion matrix in array format   \n","# annot = True: show the numbers in each heatmap cell\n","# fmt = 'd': show numbers as integers. \n","            ax = sns.heatmap(matrice_confusion, annot=True, fmt='d', )\n","\n","# set x-axis label and ticks. \n","            ax.set_xlabel(\"Prédiction \", fontsize=14, labelpad=20)\n","            ax.xaxis.set_ticklabels(['Accepté', 'Refus'])\n","\n","# set y-axis label and ticks\n","            ax.set_ylabel(\"réel \", fontsize=14, labelpad=20)\n","            ax.yaxis.set_ticklabels(['Accepté', 'Refus'])\n","\n","# set plot title\n","            titre = str(algos[i])\n","            ax.set_title(titre, fontsize=14, pad=20)\n","            plt.show()    \n","     \n","    \n","#graphique\n","\n","            roc_auc_courbe = roc_auc_score(y_train, pred_y_train_proba)\n","            print ('roc auc courbe',roc_auc_courbe)\n","            fpr,tpr,_= roc_curve(y_train,pred_y_train_proba)\n","    \n","            plt.plot(fpr,tpr,label ='score (auc roc = %0.2f)' % roc_auc_courbe)\n","            plt.plot([0,1],[0,1],'k--',label =\"random\")\n","            plt.xlabel('Taux faux positifs')\n","            plt.ylabel('Taux vrais positifs')\n","            plt.title('ROC curve '+titre)\n","            plt.legend(loc = 'lower right')\n","            plt.show()\n","            \n","           \n","            \n","            # Créer un dataframe pandas qui contient les résultats de chaque algorithme\n","            print(' score ', scorer,':' ,grid.best_score_)\n","            duration = (time.time() - debut )/60\n","            print (duration ,'minutes')\n","            Append = pd.DataFrame([[ algos[i],grid.best_params_,scorer ,grid.best_score_,sampling[s],roc_auc_train,roc_auc_discret_train\n","                                    ,roc_auc_test,roc_auc_discret_test,tn,fp,fn,tp,duration]]\n","                                  ,columns=['Algorithme','Meilleur param', 'score nom ','best score','sampling','roc_auc_train'\n","                                            ,'Roc_auc_train_discret','roc_auc_test','roc_auc_discret_test','TN','FP','FN','TP','minutes'])\n","            Report_df = pd.concat([Report_df, Append]) \n","            \n","    return Report_df"]},{"cell_type":"code","execution_count":null,"id":"d7158637-7987-4233-a781-d46082817d2e","metadata":{"tags":[],"id":"d7158637-7987-4233-a781-d46082817d2e"},"outputs":[],"source":["def nosamplerfunc(X, y):\n","    return X[:], y[:]\n","nosampler = FunctionSampler(func=nosamplerfunc)"]},{"cell_type":"markdown","id":"f4fe30d8-2c65-400e-a482-003a5329e7ac","metadata":{"id":"f4fe30d8-2c65-400e-a482-003a5329e7ac","tags":[]},"source":["# test de base , scorer roc auc"]},{"cell_type":"code","execution_count":null,"id":"34b24a0a-15bd-497b-9f42-ee5518e27300","metadata":{"id":"34b24a0a-15bd-497b-9f42-ee5518e27300","tags":[]},"outputs":[],"source":["algos = [ LogisticRegression(random_state=22),DecisionTreeClassifier(random_state=22), RandomForestClassifier(random_state=22), \n","         XGBClassifier(random_state=22), GaussianNB(),DummyClassifier()]\n","\n","# Définir une grille de paramètres à optimiser pour chaque algorithme\n","params = [\n","    \n","    {\"C\": [0.01, 0.1, 1, 10], \"penalty\": [\"l1\", \"l2\", \"elasticnet\", 'none']}, # pour LogisticRegression \n","    {\"max_depth\": [3, 5, 7], \"min_samples_leaf\": [5, 10, 15]}, # pour DecisionTreeClassifier\n","    {\"n_estimators\": [100, 200], \"max_depth\": [3, 5]}, # pour RandomForestClassifier \n","    {\"n_estimators\": [100, 200], \"learning_rate\": [0.01, 0.1]}, # pour XGBClassifier \n","    {} ,# pas de paramètres à optimiser pour GaussianNB \n","    {\"strategy\": [\"most_frequent\",\"prior\",\"stratified\",\"uniform\"]}, # pour DummyClassifier\n","] \n","\n","\"\"\"\n","algos = [ DecisionTreeClassifier(random_state=22)]\n","params = [ {\"max_depth\": [2], \"min_samples_leaf\": [3]}] # pour DecisionTreeClassifier\n","\"\"\"\n","\n","cvi =2\n","scorer = \"roc_auc\" \n","\n","\n","sampling = [nosampler, RandomOverSampler(random_state=22),RandomUnderSampler(random_state=22),SMOTETomek(random_state=22)]\n","\n","\n","\n","#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n","result_auc= comp_algos(X,y,algos,params,cvi,scorer,sampling)\n","\n","result_auc.to_excel(\"resultat_auc_200323.xlsx\")\n"]},{"cell_type":"code","execution_count":null,"id":"4d0dde0c-9b45-464e-8f65-d3567ac9c895","metadata":{"id":"4d0dde0c-9b45-464e-8f65-d3567ac9c895"},"outputs":[],"source":["\n","formatted_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(time.time()))\n","nom_excel='result_auc_'+ formatted_time +'.xlsx'\n","result_auc.to_excel(nom_excel)"]},{"cell_type":"markdown","id":"b87283b0-5da7-4b58-af28-890cbc154bc4","metadata":{"id":"b87283b0-5da7-4b58-af28-890cbc154bc4"},"source":["# test avec scorer métier "]},{"cell_type":"code","execution_count":null,"id":"ba621a39-bfde-46c3-ac51-59d1ff98680c","metadata":{"id":"ba621a39-bfde-46c3-ac51-59d1ff98680c"},"outputs":[],"source":["\"\"\" algos = [ LogisticRegression(random_state=22),DecisionTreeClassifier(random_state=22), RandomForestClassifier(random_state=22), \n","         XGBClassifier(random_state=22), GaussianNB(),DummyClassifier()]\n","\n","# Définir une grille de paramètres à optimiser pour chaque algorithme\n","params = [\n","    \n","    {\"C\": [0.01, 0.1, 1, 10], \"penalty\": [\"l1\", \"l2\", \"elasticnet\", None]}, # pour LogisticRegression ‘l1’, ‘l2’, ‘elasticnet’, None\n","    {\"max_depth\": [3, 5, 7], \"min_samples_leaf\": [5, 10, 15]}, # pour DecisionTreeClassifier\n","    {\"n_estimators\": [100, 200], \"max_depth\": [3, 5]}, # pour RandomForestClassifier \n","    {\"n_estimators\": [100, 200], \"learning_rate\": [0.01, 0.1]}, # pour XGBClassifier \n","    {} ,# pas de paramètres à optimiser pour GaussianNB \n","    {\"strategy\": [\"most_frequent\",\"prior\",\"stratified\",\"uniform\"]}, # pour DummyClassifier\n","]\n","\"\"\"\n","cvi =2\n","\n","algos = [ DecisionTreeClassifier(random_state=22)]\n","params = [ {\"max_depth\": [2,3], \"min_samples_leaf\": [2,5]}] # pour DecisionTreeClassifier\n","\n","def custom_score_func(y_true, y_pred):\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    score = tp + tn - fp -( 10 * fn)\n","    #score 2 = tp + (10 * tn )- fp -(10 * fn)\n","    return score\n","\n","# Création du scorer personnalisé\n","score_metier= make_scorer(custom_score_func)\n","\n","scorer = score_metier\n","\n","sampling = [nosampler, RandomOverSampler(random_state=22),RandomUnderSampler(random_state=22),SMOTETomek(random_state=22)]\n","\n","\n","\n","result_metier= comp_algos(X,y,algos,params,cvi,scorer,sampling)\n","result_metier"]},{"cell_type":"code","execution_count":null,"id":"b23409f3-aa97-4687-9c60-b0a3cacddc7c","metadata":{"tags":[],"id":"b23409f3-aa97-4687-9c60-b0a3cacddc7c"},"outputs":[],"source":["result_metier.to_excel(\"result_metier_190323.xlsx\")"]},{"cell_type":"raw","id":"aeee7d46-dac1-43e1-8dac-a094e1b0e9e9","metadata":{"id":"aeee7d46-dac1-43e1-8dac-a094e1b0e9e9"},"source":["formatted_time = time.strftime(\"%Y-%m-%d_%H:%M:%S\", time.localtime(time.time()))\n","nom_excel='result_metier_'+ formatted_time +'.xlsx'\n","result_metier.to_excel(nom_excel)"]},{"cell_type":"markdown","id":"8da4bc85-2f1a-4dcd-a06f-0802c4b38c0c","metadata":{"id":"8da4bc85-2f1a-4dcd-a06f-0802c4b38c0c"},"source":["# Shap feature importante"]},{"cell_type":"code","execution_count":null,"id":"c718c341-9428-46a9-b104-ceb0275c2f6a","metadata":{"id":"c718c341-9428-46a9-b104-ceb0275c2f6a"},"outputs":[],"source":["import shap"]},{"cell_type":"code","execution_count":null,"id":"5aa648df-8076-4153-9944-863a45346d07","metadata":{"id":"5aa648df-8076-4153-9944-863a45346d07"},"outputs":[],"source":["reg = RandomForestRegressor(random_state=22,max_depth =7, min_samples_split= 3, min_samples_leaf=1,n_estimators=100)\n","skf = StratifiedKFold(n_splits=5, shuffle=True,random_state=22 )\n","for train_index, test_index in skf.split(X, buildingnr['log_SiteEnergyUse(kBtu)_class']):\n","    x_train_fold, x_test_fold = X.iloc[train_index] , X.iloc[test_index]\n","    y_train_fold, y_test_fold = y[train_index], y[test_index]\n","    reg.fit(x_train_fold, y_train_fold)\n","\n","    import shap\n","shap_values = shap.TreeExplainer(reg).shap_values(x_train_fold)\n","shap.summary_plot(shap_values, x_train_fold, plot_type=\"bar\")\n","\n","explainer = shap.Explainer(reg.predict, x_test_fold)\n","# Calculates the SHAP values - It takes some time\n","shap_values = explainer(x_test_fold)"]},{"cell_type":"code","execution_count":null,"id":"98660b78-e9e6-4673-8e16-3bba6e012644","metadata":{"id":"98660b78-e9e6-4673-8e16-3bba6e012644"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n","X_resampled, y_resampled = RandomUnderSampler(random_state=22).fit_resample(X_train,y_train)\n","# entraînez votre modèle\n","#model = xgboost.train({\"learning_rate\": 0.01}, xgboost.DMatrix(X_train, label=y_train), 100)\n","#model = DecisionTreeClassifier(random_state=22, max_depth = 3, min_samples_leaf = 2)\n","model = RandomForestClassifier(n_estimators=100, random_state=0)\n","model.fit(X_resampled,y_resampled)\n","\n","\n","# expliquez les prédictions du modèle avec SHAP\n","\n","#shap_values = shap.TrExplainer(model).shap_values(x_train)\n","#classifier = transformers.pipeline('sentiment-analysis', return_all_scores=True)\n","#classifier(short_data[:2])\n","model.predict_proba(X_train)[:0]\n","\n","explainer = shap.Explainer(model)\n","shap_values = explainer(X_resampled)\n","\n","# visualisez les valeurs de Shapley pour la première observation de test\n","shap.waterfall_plot(explainer.base_values[0], values[0], X[0])\n","\n","#shap.plots.waterfall(shap_values[0])\n","shap.waterfall_plot(explainer.base_values[0], values[0][0], X[0])"]},{"cell_type":"markdown","id":"7ba97234-0d8c-4ca8-acb3-eda183220bd9","metadata":{"id":"7ba97234-0d8c-4ca8-acb3-eda183220bd9","jp-MarkdownHeadingCollapsed":true,"tags":[]},"source":["# unbalanced  oversampling score roc auc "]},{"cell_type":"code","execution_count":null,"id":"579b7c93-dcc4-4c4f-9949-5c9de82c4b50","metadata":{"id":"579b7c93-dcc4-4c4f-9949-5c9de82c4b50"},"outputs":[],"source":["algos = [ LogisticRegression(random_state=22),DecisionTreeClassifier(random_state=22), RandomForestClassifier(random_state=22), XGBClassifier(random_state=22), GaussianNB(),DummyClassifier()]\n","\n","# Définir une grille de paramètres à optimiser pour chaque algorithme\n","params = [\n","    \n","    {\"C\": [0.01, 0.1, 1, 10], \"penalty\": [\"l1\", \"l2\", \"elasticnet\", None]}, # pour LogisticRegression ‘l1’, ‘l2’, ‘elasticnet’, None\n","    {\"max_depth\": [3, 5, 7], \"min_samples_leaf\": [5, 10, 15]}, # pour DecisionTreeClassifier\n","    {\"n_estimators\": [100, 200], \"max_depth\": [3, 5]}, # pour RandomForestClassifier \n","    {\"n_estimators\": [100, 200], \"learning_rate\": [0.01, 0.1]}, # pour XGBClassifier \n","    {} ,# pas de paramètres à optimiser pour GaussianNB \n","    {\"strategy\": [\"most_frequent\",\"prior\",\"stratified\",\"uniform\"]}, # pour DummyClassifier\n","]\n","\n","cvi =2\n","scorer = \"roc_auc\"\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n","\n","# Apply oversampling\n","ros = RandomOverSampler(random_state=0)\n","X_resampled, y_resampled = ros.fit_resample(X_train,y_train)\n","\n","\n","comp_algos(X_resampled,y_resampled,X_test,y_test,algos,params,cvi,scorer)\n"]},{"cell_type":"markdown","id":"4MYFT_oTcB0B","metadata":{"id":"4MYFT_oTcB0B"},"source":["# Nouvelle section"]},{"cell_type":"markdown","id":"rOwwVwA4cCaB","metadata":{"id":"rOwwVwA4cCaB"},"source":["# Nouvelle section"]},{"cell_type":"markdown","id":"3020c2e0-e45e-4117-8474-d3a67de92c56","metadata":{"id":"3020c2e0-e45e-4117-8474-d3a67de92c56"},"source":["# unbalanced  oversampling score métier 1 "]},{"cell_type":"code","execution_count":null,"id":"c2e6f795-5aa2-40a1-ae90-38aa95808843","metadata":{"id":"c2e6f795-5aa2-40a1-ae90-38aa95808843"},"outputs":[],"source":["algos = [ LogisticRegression(random_state=22),DecisionTreeClassifier(random_state=22), RandomForestClassifier(random_state=22), XGBClassifier(random_state=22), GaussianNB(),DummyClassifier()]\n","\n","# Définir une grille de paramètres à optimiser pour chaque algorithme\n","params = [\n","    \n","    {\"C\": [0.01, 0.1, 1, 10], \"penalty\": [\"l1\", \"l2\", \"elasticnet\", None]}, # pour LogisticRegression ‘l1’, ‘l2’, ‘elasticnet’, None\n","    {\"max_depth\": [3, 5, 7], \"min_samples_leaf\": [5, 10, 15]}, # pour DecisionTreeClassifier\n","    {\"n_estimators\": [100, 200], \"max_depth\": [3, 5]}, # pour RandomForestClassifier \n","    {\"n_estimators\": [100, 200], \"learning_rate\": [0.01, 0.1]}, # pour XGBClassifier \n","    {} ,# pas de paramètres à optimiser pour GaussianNB \n","    {\"strategy\": [\"most_frequent\",\"prior\",\"stratified\",\"uniform\"]}, # pour DummyClassifier\n","]\n","\n","cvi =2\n","\n","def custom_score_func(y_true, y_pred):\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    score = tp + tn - fp -( 10 * fn)\n","    #score 2 tp + (10 * tn )- fp -(10 * fn)\n","    return score\n","\n","# Création du scorer personnalisé\n","scorer = make_scorer(custom_score_func)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n","\n","# Apply oversampling\n","ros = RandomOverSampler(random_state=0)\n","X_resampled, y_resampled = ros.fit_resample(X_train,y_train)\n","\n","\n","#comp_algos(X_resampled,y_resampled,X_test,y_test,algos,params,cvi,scorer)\n","comp_algos(X,y,algos,params,cvi,scorer,sampling)"]},{"cell_type":"markdown","id":"8e1686bc-7e34-45aa-954f-c8f396ba1095","metadata":{"id":"8e1686bc-7e34-45aa-954f-c8f396ba1095"},"source":["# undersampling  roc auc"]},{"cell_type":"code","execution_count":null,"id":"56ff538f-6d2c-4ee1-b4b5-6e39ba985196","metadata":{"id":"56ff538f-6d2c-4ee1-b4b5-6e39ba985196"},"outputs":[],"source":["algos = [ LogisticRegression(random_state=22),DecisionTreeClassifier(random_state=22), RandomForestClassifier(random_state=22), XGBClassifier(random_state=22), GaussianNB(),DummyClassifier()]\n","\n","# Définir une grille de paramètres à optimiser pour chaque algorithme\n","params = [\n","    \n","    {\"C\": [0.01, 0.1, 1, 10], \"penalty\": [\"l1\", \"l2\", \"elasticnet\", None]}, # pour LogisticRegression ‘l1’, ‘l2’, ‘elasticnet’, None\n","    {\"max_depth\": [3, 5, 7], \"min_samples_leaf\": [5, 10, 15]}, # pour DecisionTreeClassifier\n","    {\"n_estimators\": [100, 200], \"max_depth\": [3, 5]}, # pour RandomForestClassifier \n","    {\"n_estimators\": [100, 200], \"learning_rate\": [0.01, 0.1]}, # pour XGBClassifier \n","    {} ,# pas de paramètres à optimiser pour GaussianNB \n","    {\"strategy\": [\"most_frequent\",\"prior\",\"stratified\",\"uniform\"]}, # pour DummyClassifier\n","]\n","\n","cvi =2\n","scorer = \"roc_auc\"\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n","\n","# Apply undersampling\n","rus = RandomUnderSampler(random_state=22)\n","X_resampled, y_resampled = rus.fit_resample(X_train,y_train)\n","\n","\n","comp_algos(X_resampled,y_resampled,X_test,y_test,algos,params,cvi,scorer)"]},{"cell_type":"markdown","id":"00786e2e-3099-4873-a011-56aee4002800","metadata":{"id":"00786e2e-3099-4873-a011-56aee4002800"},"source":["# undersampling score metier 1"]},{"cell_type":"code","execution_count":null,"id":"5cef0891-91a3-42f3-b00e-230805c47828","metadata":{"id":"5cef0891-91a3-42f3-b00e-230805c47828"},"outputs":[],"source":["algos = [ LogisticRegression(random_state=22),DecisionTreeClassifier(random_state=22), RandomForestClassifier(random_state=22), XGBClassifier(random_state=22), GaussianNB(),DummyClassifier()]\n","\n","# Définir une grille de paramètres à optimiser pour chaque algorithme\n","params = [\n","    \n","    {\"C\": [0.01, 0.1, 1, 10], \"penalty\": [\"l1\", \"l2\", \"elasticnet\", None]}, # pour LogisticRegression ‘l1’, ‘l2’, ‘elasticnet’, None\n","    {\"max_depth\": [3, 5, 7], \"min_samples_leaf\": [5, 10, 15]}, # pour DecisionTreeClassifier\n","    {\"n_estimators\": [100, 200], \"max_depth\": [3, 5]}, # pour RandomForestClassifier \n","    {\"n_estimators\": [100, 200], \"learning_rate\": [0.01, 0.1]}, # pour XGBClassifier \n","    {} ,# pas de paramètres à optimiser pour GaussianNB \n","    {\"strategy\": [\"most_frequent\",\"prior\",\"stratified\",\"uniform\"]}, # pour DummyClassifier\n","]\n","\n","cvi =2\n","\n","def custom_score_func(y_true, y_pred):\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    score = tp + tn - fp -( 10 * fn)\n","    #score 2 tp + (10 * tn )- fp -(10 * fn)\n","    return score\n","\n","# Création du scorer personnalisé\n","scorer = make_scorer(custom_score_func)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n","\n","# Apply undersampling\n","rus = RandomUnderSampler(random_state=0)\n","X_resampled, y_resampled = rus.fit_resample(X_train,y_train)\n","\n","\n","comp_algos(X_resampled,y_resampled,X_test,y_test,algos,params,cvi,scorer)"]},{"cell_type":"markdown","id":"54c718cd-fb69-4cc9-b0a6-f19a78320fae","metadata":{"id":"54c718cd-fb69-4cc9-b0a6-f19a78320fae"},"source":["# Unbalanced SMOTE roc auc"]},{"cell_type":"code","execution_count":null,"id":"302bb835-3868-4ec9-8165-689997bd54d0","metadata":{"id":"302bb835-3868-4ec9-8165-689997bd54d0"},"outputs":[],"source":["algos = [ LogisticRegression(random_state=22),DecisionTreeClassifier(random_state=22), RandomForestClassifier(random_state=22), XGBClassifier(random_state=22), GaussianNB(),DummyClassifier()]\n","\n","# Définir une grille de paramètres à optimiser pour chaque algorithme\n","params = [\n","    \n","    {\"C\": [0.01, 0.1, 1, 10], \"penalty\": [\"l1\", \"l2\", \"elasticnet\", None]}, # pour LogisticRegression ‘l1’, ‘l2’, ‘elasticnet’, None\n","    {\"max_depth\": [3, 5, 7], \"min_samples_leaf\": [5, 10, 15]}, # pour DecisionTreeClassifier\n","    {\"n_estimators\": [100, 200], \"max_depth\": [3, 5]}, # pour RandomForestClassifier \n","    {\"n_estimators\": [100, 200], \"learning_rate\": [0.01, 0.1]}, # pour XGBClassifier \n","    {} ,# pas de paramètres à optimiser pour GaussianNB \n","    {\"strategy\": [\"most_frequent\",\"prior\",\"stratified\",\"uniform\"]}, # pour DummyClassifier\n","]\n","\n","cvi =2\n","scorer = \"roc_auc\"\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n","\n","# Apply SMOTE\n","smote = SMOTETomek(random_state=0)\n","X_resampled, y_resampled = smote.fit_resample(X_train,y_train)\n","\n","comp_algos(X_resampled,y_resampled,X_test,y_test,algos,params,cvi,scorer)"]},{"cell_type":"code","execution_count":null,"id":"nuavIJmpBiU0","metadata":{"id":"nuavIJmpBiU0"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","id":"c9cfd134-4a4b-477a-8edd-44be0e35efb3","metadata":{"id":"c9cfd134-4a4b-477a-8edd-44be0e35efb3"},"source":["# Unbalanced SMOTE métier 1"]},{"cell_type":"code","execution_count":null,"id":"0b5e6c82-1e18-4cea-97ea-e5989ad29c2b","metadata":{"id":"0b5e6c82-1e18-4cea-97ea-e5989ad29c2b"},"outputs":[],"source":["algos = [ LogisticRegression(random_state=22),DecisionTreeClassifier(random_state=22), RandomForestClassifier(random_state=22), XGBClassifier(random_state=22), GaussianNB(),DummyClassifier()]\n","\n","# Définir une grille de paramètres à optimiser pour chaque algorithme\n","params = [\n","    \n","    {\"C\": [0.01, 0.1, 1, 10], \"penalty\": [\"l1\", \"l2\", \"elasticnet\", None]}, # pour LogisticRegression ‘l1’, ‘l2’, ‘elasticnet’, None\n","    {\"max_depth\": [3, 5, 7], \"min_samples_leaf\": [5, 10, 15]}, # pour DecisionTreeClassifier\n","    {\"n_estimators\": [100, 200], \"max_depth\": [3, 5]}, # pour RandomForestClassifier \n","    {\"n_estimators\": [100, 200], \"learning_rate\": [0.01, 0.1]}, # pour XGBClassifier \n","    {} ,# pas de paramètres à optimiser pour GaussianNB \n","    {\"strategy\": [\"most_frequent\",\"prior\",\"stratified\",\"uniform\"]}, # pour DummyClassifier\n","]\n","\n","cvi =2\n","\n","def custom_score_func(y_true, y_pred):\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    score = tp + tn - fp -( 10 * fn)\n","    #score 2 tp + (10 * tn )- fp -(10 * fn)\n","    return score\n","\n","# Création du scorer personnalisé\n","scorer = make_scorer(custom_score_func)\n","\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n","\n","# Apply SMOTE\n","smote = SMOTETomek(random_state=0)\n","X_resampled, y_resampled = smote.fit_resample(X_train,y_train)\n","\n","comp_algos(X_resampled,y_resampled,X_test,y_test,algos,params,cvi,scorer)"]},{"cell_type":"markdown","id":"f01f8c67-dd40-40fc-b9ca-9da1c16fe16f","metadata":{"id":"f01f8c67-dd40-40fc-b9ca-9da1c16fe16f"},"source":["# individuel"]},{"cell_type":"code","execution_count":null,"id":"5eed5ddc","metadata":{"id":"5eed5ddc"},"outputs":[],"source":["#LogisticRegression() {'C': 1, 'penalty': 'l2'} \n","grid = GridSearchCV(estimator=algos[i], param_grid=params[i], scoring=\"roc_auc\", cv=3, refit= True )"]},{"cell_type":"code","execution_count":null,"id":"28a51e6a-2856-4e9e-bd86-642e0a5b73ae","metadata":{"id":"28a51e6a-2856-4e9e-bd86-642e0a5b73ae"},"outputs":[],"source":["\n","nsplit = 3\n","    \n","    \n","debut = time.time()\n","\n","\n","\n","estimator = DecisionTreeClassifier(max_depth=7, min_samples_leaf=15)\n","\n","numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])  \n","\n","clf = Pipeline(steps=[ #('preprocessor', numeric_transformer),\n","                      ('estimator', estimator) ])\n","\n","\n","skf = StratifiedKFold(n_splits=nsplit, shuffle=True,random_state=22 ) \n","\n","\n","for train_index, test_index in skf.split(X, y):\n","    x_train, x_test = X.iloc[train_index] , X.iloc[test_index]\n","    y_train, y_test = y[train_index], y[test_index]\n","    clf.fit(x_train, y_train) \n","\n","    \n","#c faire tourner le prédict\n","pred_y = clf.predict(x_test)\n","score = accuracy_score(y_test,pred_y)\n","print ('accuracy test ',score)\n","roc_auc = roc_auc_score(y_test, pred_y)\n","print ( 'roc_auc_  test ',roc_auc)\n","\n","\n","pred_y_train = clf.predict(x_train)\n","score = accuracy_score(y_train,pred_y_train)\n","print ('accuracy train ',score)\n","roc_auc = roc_auc_score(y_train, pred_y_train)\n","print ( 'roc_auc_  train ',roc_auc)"]},{"cell_type":"code","execution_count":null,"id":"3882307b-7b1d-4e11-82a9-36be14d5080b","metadata":{"id":"3882307b-7b1d-4e11-82a9-36be14d5080b"},"outputs":[],"source":["\n","nsplit = 3\n","    \n","    \n","debut = time.time()\n","\n","grid = GridSearchCV(estimator=DecisionTreeClassifier(), \n","                                param_grid={\"max_depth\": [3, 5, 7], \"min_samples_leaf\": [5, 10, 15]}, scoring=\"roc_auc\", cv=3, refit= True )\n","\n","\n","grid.fit(X,y)\n","\n","# Afficher le meilleur score et le meilleur algorithme trouvé par GridSearchCV \n","print(\"Meilleur score:\", grid.best_score_)\n","print(\"Meilleur algorithme:\", grid.best_estimator_)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"1d0feedb-7485-4429-8b55-412f9b56a498","metadata":{"id":"1d0feedb-7485-4429-8b55-412f9b56a498"},"outputs":[],"source":["from sklearn.metrics import auc\n","from sklearn.model_selection import train_test_split\n","# Split data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n","\n","# Fit GridSearchCV on training data\n","grid = GridSearchCV(estimator=DecisionTreeClassifier(), \n","                    param_grid={\"max_depth\": [3, 5, 7], \"min_samples_leaf\": [5, 10, 15]}, \n","                    scoring=\"roc_auc\", cv=3)\n","grid.fit(X_train,y_train)\n","\n","# Make predictions on test data using best_estimator_\n","y_pred = grid.best_estimator_.predict_proba(X_test)[:,1]\n","\n","# Calculate FPR and TPR\n","fpr, tpr, thresholds = roc_curve(y_test,y_pred)\n","\n","# Calculate AUC\n","roc_auc = auc(fpr,tpr)\n","\n","# Plot ROC curve\n","plt.plot(fpr,tpr,label='ROC curve (area = %0.2f)' % roc_auc)\n","plt.plot([0,1],[0,1],'k--')\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Receiver Operating Characteristic')\n","plt.legend(loc=\"lower right\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"e20acdf2-d4b2-400e-9a95-005beb58c404","metadata":{"id":"e20acdf2-d4b2-400e-9a95-005beb58c404"},"outputs":[],"source":["grid = GridSearchCV(estimator=DecisionTreeClassifier, param_grid={\"max_depth\": [3, 5, 7], \"min_samples_leaf\": [5, 10, 15]}, scoring=\"roc_auc\", cv=3, refit= True )"]},{"cell_type":"code","execution_count":null,"id":"73c2486c-371d-4dbb-86e8-3f49ac61f9ad","metadata":{"id":"73c2486c-371d-4dbb-86e8-3f49ac61f9ad"},"outputs":[],"source":["\n","      \n","    \n","    \n","    \n","\"\"\" Append= pd.DataFrame([['RandomForest' , \n","                        np.around (mean_squared_error(y_test,reg.predict(x_test)),3),\n","                       np.around (mean_squared_error(y_test,reg.predict(x_test),squared=False),3),\n","                      np.around(r2_score(y_test,reg.predict(x_test)),3),\n","                     np.around( mean_absolute_percentage_error(y_test,reg.predict(x_test)),3),\n","                      np.around(r2_score(y_train,reg.predict(x_train)),3) ,\n","                      time.time() - debut]], \n","                     columns=['méthode', 'MSE','RMSE','R2 Test','MA%E','R2 Train','Durée'])\n","    \n","\n","Report = pd.concat([Report, Append]) \n","Report\"\"\" \n","    "]},{"cell_type":"code","execution_count":null,"id":"d66672f1-cffd-418e-818b-fb4cdd4cb02d","metadata":{"id":"d66672f1-cffd-418e-818b-fb4cdd4cb02d"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"6a0e628a","metadata":{"id":"6a0e628a"},"outputs":[],"source":["\n","\n","# Calculer le score roc_auc pour chaque algorithme \n","    roc_aucs = []\n","    for i in range(len(algos)):\n","        roc_aucs.append(roc_auc_score(y_true=y,y_score=probas[:,i]))\n","\n","# Créer un dataframe pandas qui contient les scores roc_auc de chaque algorithme \n","    roc_df = pd.DataFrame({\"Algorithme\": algos,\"ROC_AUC\": roc_aucs})\n","    print(roc_df)\n","\n","# Prédire les classes pour chaque algorithme \n","    preds = grid.predict(X)\n","\n","# Calculer la matrice de confusion pour chaque algorithme \n","    confusions = []\n","    for i in range(len(algos)):\n","        confusions.append(confusion_matrix(y_true=y,y_pred=preds[:,i]))\n","\n","# Créer un dataframe pandas qui contient les matrices de confusion de chaque algorithme \n","    conf_df = pd.DataFrame({\"Algorithme\": algos,\"Confusion Matrix\": confusions})\n","    print(conf_df)"]},{"cell_type":"code","execution_count":null,"id":"ea3e7505","metadata":{"id":"ea3e7505"},"outputs":[],"source":["# Importer la bibliothèque Keras Tuner qui permet de faire de l'optimisation bayésienne\n","from kerastuner.tuners import BayesianOptimization\n","\n","# Définir une fonction qui crée un modèle de classification naïve bayésienne avec des hyperparamètres à optimiser\n","def build_model(hp):\n","    # Créer un objet GaussianNB \n","    model = GaussianNB()\n","    # Définir les hyperparamètres à optimiser: le lissage de Laplace (var_smoothing) et le seuil de décision (threshold)\n","    hp_var_smoothing = hp.Float('var_smoothing', 1e-9, 1e-3, sampling='log')\n","    hp_threshold = hp.Float('threshold', 0.0, 1.0)\n","    # Affecter les valeurs des hyperparamètres au modèle \n","    model.var_smoothing = hp_var_smoothing\n","    model.threshold = hp_threshold\n","    # Retourner le modèle \n","    return model\n","\n","# Créer un objet BayesianOptimization qui va comparer les performances du modèle sur les données en utilisant le score roc_auc comme critère d'évaluation \n","tuner = BayesianOptimization(build_model,\n","                             objective='roc_auc',\n","                             max_trials=10,\n","                             executions_per_trial=1)\n","\n","# Lancer la recherche des meilleurs hyperparamètres pour le modèle \n","tuner.search(X,y)\n","\n","# Afficher les meilleurs hyperparamètres trouvés par BayesianOptimization \n","print(\"Meilleurs hyperparamètres:\", tuner.get_best_hyperparameters()[0].values)\n","\n","# Prédire les probabilités des classes pour le modèle optimisé \n","proba_bayes = tuner.predict(X)\n","\n","# Calculer le score roc_auc pour le modèle optimisé \n","roc_auc_bayes = roc_auc_score(y_true=y,y_score=proba_bayes)\n","\n","# Ajouter le score roc_auc du modèle optimisé au dataframe pandas qui contient les scores roc_auc de chaque algorithme \n","roc_df.loc[len(roc_df)] = [\"GaussianNB Optimized\", roc_auc_bayes]\n","print(roc_df)\n","\n","# Prédire les classes pour le modèle optimisé \n","pred_bayes = tuner.predict_classes(X)\n","\n","# Calculer la matrice de confusion pour le modèle optimisé \n","confusion_bayes = confusion_matrix(y_true=y,y_pred=pred_bayes)\n","\n","# Ajouter la matrice de confusion du modèle optimisé au dataframe pandas qui contient les matrices de confusion de chaque algorithme \n","conf_df.loc[len(conf_df)] = [\"GaussianNB Optimized\", confusion_bayes]\n","print(conf_df)"]},{"cell_type":"code","execution_count":null,"id":"2ce81002","metadata":{"id":"2ce81002"},"outputs":[],"source":["# Importer la bibliothèque matplotlib.pyplot qui permet de faire des graphiques \n","import matplotlib.pyplot as plt\n","\n","# Créer une figure avec une taille de 10x10 pouces \n","plt.figure(figsize=(10,10))\n","\n","# Parcourir chaque algorithme dans le dataframe roc_df qui contient les scores roc_auc de chaque algorithme \n","for index, row in roc_df.iterrows():\n","    # Récupérer le nom de l'algorithme et le score roc_auc \n","    algo = row[\"Algo\"]\n","    score = row[\"ROC_AUC\"]\n","    # Calculer les taux de faux positifs (fpr) et de vrais positifs (tpr) en utilisant la fonction roc_curve de sklearn.metrics \n","    fpr, tpr, thresholds = roc_curve(y_true=y,y_score=proba_dict[algo])\n","    # Tracer la courbe ROC en utilisant la fonction plot de matplotlib.pyplot \n","    plt.plot(fpr,tpr,label=f\"{algo} (AUC={score:.3f})\")\n","\n","# Ajouter un titre au graphique \n","plt.title(\"Courbes ROC des différents algorithmes\")\n","\n","# Ajouter des légendes aux axes x et y \n","plt.xlabel(\"Taux de faux positifs\")\n","plt.ylabel(\"Taux de vrais positifs\")\n","\n","# Ajouter une grille au graphique pour faciliter la lecture \n","plt.grid()\n","\n","# Ajouter une ligne diagonale qui représente un classifieur aléatoire \n","plt.plot([0,1],[0,1],linestyle=\"--\",color=\"black\",label=\"Aléatoire\")\n","\n","# Ajouter une légende au graphique pour identifier chaque courbe ROC \n","plt.legend()\n","\n","# Afficher le graphique à l'écran \n","plt.show()\n"]},{"cell_type":"markdown","id":"3a229cb5","metadata":{"id":"3a229cb5"},"source":["Les courbes ROC permettent d’évaluer les performances d’un modèle de classification en fonction du seuil de décision choisi. Elles représentent le taux de vrais positifs (TPR) en fonction du taux de faux positifs (FPR) pour différents seuils. Plus la courbe est proche du coin supérieur gauche du graphique, plus le modèle est performant. L’aire sous la courbe (AUC) est une mesure synthétique qui résume la qualité d’un modèle: plus elle est proche de 1, mieux c’est.\n","\n","Sur ce graphique, on peut voir que le modèle optimisé par l’optimisation bayésienne a la meilleure performance parmi tous les modèles testés. Il a une AUC élevée et il domine les autres courbes sur tout l’intervalle des FPR. Cela signifie qu’il a un bon compromis entre sensibilité et spécificité."]},{"cell_type":"code","execution_count":null,"id":"91799052","metadata":{"id":"91799052"},"outputs":[],"source":["# Importer les bibliothèques nécessaires\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import roc_curve\n","import pandas as pd\n","\n","# Créer un dataframe pandas avec les étiquettes réelles et les probabilités prédites\n","y_true = [0, 0, 0, 1, 1, 1]\n","y_pred = [0.1, 0.2, 0.3, 0.7, 0.8, 0.9]\n","df = pd.DataFrame({\"y_true\": y_true,\"y_pred\": y_pred})\n","\n","# Calculer les taux de faux positifs et de vrais positifs pour chaque classe\n","fpr_0,tpr_0,_ = roc_curve(y_true=df[\"y_true\"],y_score=1-df[\"y_pred\"],pos_label=0)\n","fpr_1,tpr_1,_ = roc_curve(y_true=df[\"y_true\"],y_score=df[\"y_pred\"],pos_label=1)\n","\n","# Créer un objet FacetGrid avec seaborn\n","g = sns.FacetGrid(df,hue=\"y_true\",height=5)\n","\n","# Appliquer la fonction plot à chaque sous-graphique avec la méthode map\n","g.map(plt.plot,fpr_0,tpr_0,label=\"Classe 0\")\n","g.map(plt.plot,fpr_1,tpr_1,label=\"Classe 1\")\n","\n","# Ajouter des titres, des légendes et des annotations au graphique\n","g.set_axis_labels(\"Taux de faux positifs\",\"Taux de vrais positifs\")\n","g.fig.suptitle(\"Courbes ROC avec seaborn\")\n","g.add_legend()\n","plt.plot([0,1],[0,1],linestyle=\"--\",color=\"black\",label=\"Aléatoire\")\n","plt.show()"]},{"cell_type":"markdown","id":"f5e80281-1b69-425a-a73a-191c23fcdc9b","metadata":{"id":"f5e80281-1b69-425a-a73a-191c23fcdc9b"},"source":["# "]}],"metadata":{"colab":{"provenance":[{"file_id":"1Jt7PiO9zRBoNGlNKSwcQjEsl9iIAL951","timestamp":1679311336338},{"file_id":"1SGZ4mvrsrO3TDJ09fHbiDpTiAaYwFevg","timestamp":1679307281408}],"toc_visible":true},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"toc-autonumbering":true,"toc-showcode":false,"toc-showmarkdowntxt":false,"toc-showtags":true},"nbformat":4,"nbformat_minor":5}